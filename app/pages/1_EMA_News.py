"""
EMA News Scraper - EMAãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸
"""
import logging
import os
from datetime import datetime
from typing import List, Dict

import streamlit as st
import tempfile
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šï¼‰
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '..', '.env'))

from scrapers.ema_scraper import scrape_ema_news
from shared.gpt_html import generate_html_from_articles
from config import DEFAULT_DAYS_BACK, OPENAI_API_KEY

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #2c3e50;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-message {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #c3e6cb;
        margin: 1rem 0;
    }
    .error-message {
        background-color: #f8d7da;
        color: #721c24;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #f5c6cb;
        margin: 1rem 0;
    }
    .info-message {
        background-color: #d1ecf1;
        color: #0c5460;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #bee5eb;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


def validate_environment() -> bool:
    """ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼"""
    if not OPENAI_API_KEY:
        st.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info("ğŸ’¡ .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return False
    return True


def display_article_preview(articles: List[Dict[str, str]]) -> None:
    """è¨˜äº‹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º"""
    if not articles:
        st.warning("ğŸ“­ æŒ‡å®šæœŸé–“å†…ã«è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    st.subheader(f"ğŸ“° å–å¾—ã—ãŸè¨˜äº‹ ({len(articles)}ä»¶)")
    
    for i, article in enumerate(articles, 1):
        with st.expander(f"{i}. {article['title'][:80]}..."):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {article['title']}")
                st.write(f"**å…¬é–‹æ—¥:** {article['published_at_iso']}")
                st.write(f"**è¦ç´„:** {article['summary_or_lead']}")
            
            with col2:
                st.link_button("ğŸ”— è¨˜äº‹ã‚’èª­ã‚€", article['url'])


def save_html_to_file(html_content: str) -> str:
    """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ema_news_{timestamp}.html"
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
        f.write(html_content)
        temp_path = f.name
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
    project_path = os.path.join(os.getcwd(), filename)
    with open(project_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return project_path


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown('<h1 class="main-header">ğŸ‡ªğŸ‡º EMA News Scraper</h1>', unsafe_allow_html=True)
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not validate_environment():
        st.stop()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    st.sidebar.header("âš™ï¸ è¨­å®š")
    
    # å¯¾è±¡æœŸé–“
    days_back = st.sidebar.slider(
        "ğŸ“… å¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰",
        min_value=1,
        max_value=30,
        value=DEFAULT_DAYS_BACK,
        help="ä½•æ—¥å‰ã‹ã‚‰ã®è¨˜äº‹ã‚’å–å¾—ã™ã‚‹ã‹"
    )
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºè¨­å®š
    show_preview = st.sidebar.checkbox(
        "ğŸ‘ï¸ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º",
        value=True,
        help="ç”Ÿæˆã•ã‚ŒãŸHTMLã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ã‹"
    )
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    st.markdown("### ğŸ¯ ä½¿ç”¨æ–¹æ³•")
    st.markdown("""
    1. å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å¯¾è±¡æœŸé–“ã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7æ—¥é–“ï¼‰
    2. ã€ŒğŸ“° è¨˜äº‹ã‚’å–å¾—ãƒ»è¦ç´„ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° â†’ ChatGPTè¦ç´„ â†’ HTMLç”ŸæˆãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™
    4. ç”Ÿæˆã•ã‚ŒãŸHTMLã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
    
    **æ©Ÿèƒ½**: EMAãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è‡ªå‹•å–å¾—ã¨ChatGPTã«ã‚ˆã‚‹è©³ç´°è¦ç´„
    """)
    
    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        run_button = st.button(
            "ğŸ“° è¨˜äº‹ã‚’å–å¾—ãƒ»è¦ç´„",
            type="primary",
            use_container_width=True
        )
    
    if run_button:
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Step 1: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
            status_text.text("ğŸ” EMAãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­...")
            progress_bar.progress(25)
            
            articles = scrape_ema_news(days_back)
            
            if not articles:
                st.warning("ğŸ“­ æŒ‡å®šæœŸé–“å†…ã«è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.stop()
            
            # Step 2: ChatGPTè¦ç´„ãƒ»HTMLç”Ÿæˆ
            status_text.text("ğŸ¤– ChatGPTã§è¨˜äº‹ã‚’è¦ç´„ãƒ»HTMLç”Ÿæˆä¸­...")
            progress_bar.progress(75)
            
            html_content = generate_html_from_articles(articles)
            
            progress_bar.progress(100)
            
            st.markdown('<div class="success-message">âœ… è¨˜äº‹ã®å–å¾—ãƒ»è¦ç´„ãŒå®Œäº†ã—ã¾ã—ãŸï¼</div>', unsafe_allow_html=True)
            status_text.text("âœ… å®Œäº†")
            
            # çµ±è¨ˆæƒ…å ±
            st.success(f"""
            ğŸ“Š **å‡¦ç†å®Œäº†**
            - å–å¾—è¨˜äº‹æ•°: {len(articles)}ä»¶
            - å¯¾è±¡æœŸé–“: éå»{days_back}æ—¥é–“
            - ChatGPTè¦ç´„: å®Œäº†
            - HTMLç”Ÿæˆ: å®Œäº†
            """)
        
        except Exception as e:
            st.markdown('<div class="error-message">âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚</div>', unsafe_allow_html=True)
            st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            logger.error(f"Error in main process: {e}")
            status_text.text("âŒ ã‚¨ãƒ©ãƒ¼")
        
        finally:
            progress_bar.empty()
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    if show_preview and 'html_content' in locals():
        st.markdown("---")
        st.subheader("ğŸ‘ï¸ HTMLãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        html_file_path = save_html_to_file(html_content)
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
        st.components.v1.html(html_content, height=600, scrolling=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        with open(html_file_path, 'r', encoding='utf-8') as f:
            html_data = f.read()
        
        st.download_button(
            label="ğŸ’¾ HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=html_data,
            file_name=f"ema_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
            mime="text/html"
        )
    
    # è¨˜äº‹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if 'articles' in locals() and articles:
        st.markdown("---")
        display_article_preview(articles)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #7f8c8d; font-size: 0.9em;">
        <p>ğŸ‡ªğŸ‡º EMA News Scraper | Data source: European Medicines Agency (EMA)</p>
        <p>ğŸ¤– ChatGPTè¦ç´„æ©Ÿèƒ½ä»˜ã | å€‹äººåˆ©ç”¨ç›®çš„ã€‚EMAã®Legal noticeã«åŸºã¥ãã€å‡ºå…¸ã‚’æ˜ç¤ºã—ã¦ã„ã¾ã™ã€‚</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
